{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Architecture\n",
    "\n",
    "For now we have `Tweets` and `Price History` as our primary data source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Main Architecture](main_architecture.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tweets` are first `Pre-Processed` and then `Classified` using a simple `Neural Network` which later will be converted into a `Convolutional Neural Network`. The `Tweets` are filtered in `realtime` and stored in the database.\n",
    "\n",
    "Steps in Pre-Process:\n",
    "1. remove tweets with `#Tags > 3`\n",
    "2. lowercase\n",
    "3. remove stopwords\n",
    "4. remove urls\n",
    "5. remove any symbols\n",
    "\n",
    "Steps in Classification:\n",
    "1. vectorize with `Bag of Words`\n",
    "2. vectorize with `Term Frequency - Inverse Document Frequency (TFIDF)`\n",
    "3. filter with `Neural Network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vectorized Tweets` are clustered per day. For now `Spectral Clustering` (`Hierarchical Clustering` will also be tested). The clustered dataset is then fed into a `Neural Network` to produce `Good Tweets Cluster`, `Bad Tweets Cluster` or both as applicable. \n",
    "\n",
    "Steps in `Pre-Process`:\n",
    "1. remove tweets with `#Tags > 3`\n",
    "2. lowercase\n",
    "3. remove stopwords\n",
    "4. remove urls\n",
    "5. remove any symbols\n",
    "6. sort in ascending order\n",
    "7. get tweets for a day\n",
    "\n",
    "Steps in Clustering:\n",
    "1. vectorize with `Bag of Words`\n",
    "2. vectorize with `Term Frequency - Inverse Document Frequency (TFIDF)`\n",
    "3. <s>reduce vector dimention with `Latent Semantic Analysis (LSA)` via `Singular Vector Decomposition (SVD)`</s>. Not Required as `Neural Network` is capable of identifying text patterns and thus more data is better.\n",
    "4. normalize vector\n",
    "5. cluster with `Spectral Clustering`\n",
    "6. filter cluster with `Neural Network`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Good/Bad Clustered Tweets` are fed into a `Neural Network`. Cluster tweets of both `Good` and `Bad`. Count tweets per cluster and pick top tweets of either category. Sum counts for each group and normalize the count values. Return the `absolute difference` of the two groups.\n",
    "\n",
    "##### This can be further taken into predicting the `Delta Price` for the next day.\n",
    "`Delta Price` is calculate with a moving average of previous 10 days.\n",
    "Feed the vectors into a `Neural Network` which should produce an output equivalent to `Delta Price`.\n",
    "\n",
    "Steps in `Pre-Process`:\n",
    "1. remove tweets with `#Tags > 3`\n",
    "2. lowercase\n",
    "3. remove stopwords\n",
    "4. remove urls\n",
    "5. remove any symbols\n",
    "\n",
    "Steps in Clustering:\n",
    "1. vectorize with `Bag of Words`\n",
    "2. vectorize with `Term Frequency - Inverse Document Frequency (TFIDF)`\n",
    "3. <s>reduce vector dimention with `Latent Semantic Analysis (LSA)` via `Singular Vector Decomposition (SVD)`</s>. Not Required as `Neural Network` is capable of identifying text patterns and thus more data is better.\n",
    "4. cluster with `Spectral Clustering`\n",
    "6. count items in cluster and normalize the value\n",
    "7. return difference of the two groups.\n",
    "\n",
    "May extend the functionality\n",
    "\n",
    "8. regression to predict `Delta Price`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Price ranges of various CryptoCurrencies including `High`,`Low`,`Open`,`Close` along with the `Sentiment` value and `Delta Price` obtained by training the tweets are fed into the model to keep predicting prices in the near future until there is a considerable change rise/dip in the price plot and hence depicting a change in trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps in Data Preprocessing:\n",
    "1. Normalize dataset\n",
    "2. Prepare output labels\n",
    "3. Split into Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps in defining the model:\n",
    "1. Set the `input size` [No. of Features]\n",
    "2. Set the `output size` [No. of Features predicted to feed next]\n",
    "3. Set the `num_size` [Length of sequence fed into the model, which is 1 in our case as we feed only one day's data]\n",
    "4. Set the `lstm_size` [The number of units in the LSTM cell]\n",
    "5. Fetch processed Data\n",
    "6. Send data to model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps after model training:\n",
    "1. Train the model\n",
    "2. Plot graph between predicted and actual values\n",
    "3. Take the test_pred and feed it into the model to predict the prices for the next day\n",
    "4. Keep repeating step 4 until the predicted value falls out of the `Delta Price`\n",
    "5. Return the final prediction\n",
    "6. Save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
